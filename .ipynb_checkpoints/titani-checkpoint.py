# ========================================
# TP2 TITANIC ‚Äì MACHINE LEARNING INTERACTIF AVEC STREAMLIT
# ========================================

import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# -------------------------------
# CONFIGURATION DE LA PAGE
# -------------------------------
st.set_page_config(page_title="TP2 Titanic ML", layout="wide")
st.title("üö¢ Machine Learning sur le Titanic Dataset")
st.markdown("### INF 365 ‚Äì Ing√©nierie de Donn√©e")

st.sidebar.header("‚öôÔ∏è Param√®tres de l'application")

# -------------------------------
# 1Ô∏è‚É£ CHARGEMENT DU FICHIER
# -------------------------------
uploaded_file = st.sidebar.file_uploader("üìÇ Importer le fichier Titanic (CSV)", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.success("‚úÖ Fichier charg√© avec succ√®s !")

    # Aper√ßu du dataset
    st.subheader("üìã Aper√ßu des donn√©es")
    st.dataframe(df.head())

    # Informations g√©n√©rales
    st.subheader("‚ÑπÔ∏è Informations g√©n√©rales")
    st.write("**Nombre de lignes et colonnes :**", df.shape)
    st.write("**Valeurs manquantes :**")
    st.dataframe(df.isnull().sum())

    # -------------------------------
    # 2Ô∏è‚É£ PR√âTRAITEMENT
    # -------------------------------
    st.subheader("üßπ Nettoyage et Pr√©traitement des Donn√©es")

    numeric_cols = df.select_dtypes(include=np.number).columns
    categorical_cols = df.select_dtypes(exclude=np.number).columns

    # Imputation des valeurs manquantes
    imputer_num = SimpleImputer(strategy='median')
    imputer_cat = SimpleImputer(strategy='most_frequent')

    df[numeric_cols] = imputer_num.fit_transform(df[numeric_cols])
    df[categorical_cols] = imputer_cat.fit_transform(df[categorical_cols])

    # Encodage
    encoder = LabelEncoder()
    for col in categorical_cols:
        df[col] = encoder.fit_transform(df[col])

    # Normalisation
    scaler = StandardScaler()
    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

    st.success("‚úÖ Donn√©es nettoy√©es, encod√©es et normalis√©es avec succ√®s !")

    # -------------------------------
    # 3Ô∏è‚É£ S√âPARATION TRAIN / TEST
    # -------------------------------
    if "Survived" not in df.columns:
        st.error("‚ùå La colonne 'Survived' (variable cible) est manquante dans le dataset.")
    else:
        # X = df.drop("Survived", axis=1)
        # y = df["Survived"]
        X = df.drop("Survived", axis=1)
        y = df["Survived"]

# üîß Correction : forcer les √©tiquettes √† √™tre de type entier (classification)
        y = y.round().astype(int)


        test_size = st.sidebar.slider("üìä Taille de l‚Äôensemble de test (%)", 10, 50, 20)
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size/100, random_state=42
        )

        st.write(f"**Taille de l‚Äôensemble d‚Äôentra√Ænement :** {X_train.shape}")
        st.write(f"**Taille de l‚Äôensemble de test :** {X_test.shape}")

        # -------------------------------
        # 4Ô∏è‚É£ CHOIX DU MOD√àLE
        # -------------------------------
        st.sidebar.subheader("üß† Choix du mod√®le")
        model_choice = st.sidebar.selectbox(
            "S√©lectionnez un algorithme :",
            ["KNN", "SVM", "Random Forest", "R√©gression Logistique"]
        )

        if st.sidebar.button("üöÄ Entra√Æner le mod√®le"):
            if model_choice == "KNN":
                model = KNeighborsClassifier()
            elif model_choice == "SVM":
                model = SVC()
            elif model_choice == "Random Forest":
                model = RandomForestClassifier()
            else:
                model = LogisticRegression(max_iter=1000)

            # Entra√Ænement
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            acc = accuracy_score(y_test, y_pred)
            cm = confusion_matrix(y_test, y_pred)

            st.subheader("üìà R√©sultats du Mod√®le")
            st.write(f"**Exactitude (Accuracy)** : {acc:.4f}")
            st.text("üìä Rapport de classification :")
            st.text(classification_report(y_test, y_pred))

            # Matrice de confusion graphique
            st.subheader("üîç Matrice de Confusion")
            fig, ax = plt.subplots()
            sns.heatmap(cm, annot=True, cmap="Blues", fmt="d", ax=ax)
            st.pyplot(fig)

        # -------------------------------
        # 5Ô∏è‚É£ OPTIMISATION DES HYPERPARAM√àTRES
        # -------------------------------
        st.sidebar.subheader("üéØ Optimisation GridSearchCV")

        if st.sidebar.button("üîé Lancer l‚Äôoptimisation"):
            if model_choice == "KNN":
                param_grid = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance']}
                grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')
            elif model_choice == "Random Forest":
                param_grid = {
                    'n_estimators': [50, 100, 200],
                    'max_depth': [5, 10, None],
                    'min_samples_split': [2, 5, 10]
                }
                grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')
            else:
                st.warning("‚ö†Ô∏è L‚Äôoptimisation est uniquement disponible pour KNN et Random Forest.")
                grid = None

            if grid is not None:
                with st.spinner("‚è≥ Recherche des meilleurs param√®tres..."):
                    grid.fit(X_train, y_train)
                st.success("‚úÖ Optimisation termin√©e !")
                st.write("**Meilleurs param√®tres :**", grid.best_params_)
                st.write("**Meilleure pr√©cision (cross-validation)** :", grid.best_score_)

else:
    st.info("üì• Veuillez importer un fichier Titanic CSV pour commencer.")
