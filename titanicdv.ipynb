{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92830b57-24ac-4b32-9dbf-5bcbf3b6ada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# TP2 TITANIC ‚Äì MACHINE LEARNING INTERACTIF AVEC STREAMLIT\n",
    "# ========================================\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIGURATION DE LA PAGE\n",
    "# -------------------------------\n",
    "st.set_page_config(page_title=\"TP2 Titanic ML\", layout=\"wide\")\n",
    "st.title(\"üö¢ TP2 ‚Äì Machine Learning sur le Titanic Dataset\")\n",
    "st.markdown(\"### INF 325 ‚Äì Ing√©nierie de Donn√©e\")\n",
    "\n",
    "st.sidebar.header(\"‚öôÔ∏è Param√®tres de l'application\")\n",
    "\n",
    "# -------------------------------\n",
    "# 1Ô∏è‚É£ CHARGEMENT DU FICHIER\n",
    "# -------------------------------\n",
    "uploaded_file = st.sidebar.file_uploader(\"üìÇ Importer le fichier Titanic (CSV)\", type=[\"csv\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    df = pd.read_csv(uploaded_file)\n",
    "    st.success(\"‚úÖ Fichier charg√© avec succ√®s !\")\n",
    "\n",
    "    # Aper√ßu du dataset\n",
    "    st.subheader(\"üìã Aper√ßu des donn√©es\")\n",
    "    st.dataframe(df.head())\n",
    "\n",
    "    # Informations g√©n√©rales\n",
    "    st.subheader(\"‚ÑπÔ∏è Informations g√©n√©rales\")\n",
    "    st.write(\"**Nombre de lignes et colonnes :**\", df.shape)\n",
    "    st.write(\"**Valeurs manquantes :**\")\n",
    "    st.dataframe(df.isnull().sum())\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2Ô∏è‚É£ PR√âTRAITEMENT\n",
    "    # -------------------------------\n",
    "    st.subheader(\"üßπ Nettoyage et Pr√©traitement des Donn√©es\")\n",
    "\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "    categorical_cols = df.select_dtypes(exclude=np.number).columns\n",
    "\n",
    "    # Imputation des valeurs manquantes\n",
    "    imputer_num = SimpleImputer(strategy='median')\n",
    "    imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "    df[numeric_cols] = imputer_num.fit_transform(df[numeric_cols])\n",
    "    df[categorical_cols] = imputer_cat.fit_transform(df[categorical_cols])\n",
    "\n",
    "    # Encodage\n",
    "    encoder = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "    # Normalisation\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    st.success(\"‚úÖ Donn√©es nettoy√©es, encod√©es et normalis√©es avec succ√®s !\")\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3Ô∏è‚É£ S√âPARATION TRAIN / TEST\n",
    "    # -------------------------------\n",
    "    if \"Survived\" not in df.columns:\n",
    "        st.error(\"‚ùå La colonne 'Survived' (variable cible) est manquante dans le dataset.\")\n",
    "    else:\n",
    "        X = df.drop(\"Survived\", axis=1)\n",
    "        y = df[\"Survived\"]\n",
    "\n",
    "        test_size = st.sidebar.slider(\"üìä Taille de l‚Äôensemble de test (%)\", 10, 50, 20)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size/100, random_state=42\n",
    "        )\n",
    "\n",
    "        st.write(f\"**Taille de l‚Äôensemble d‚Äôentra√Ænement :** {X_train.shape}\")\n",
    "        st.write(f\"**Taille de l‚Äôensemble de test :** {X_test.shape}\")\n",
    "\n",
    "        # -------------------------------\n",
    "        # 4Ô∏è‚É£ CHOIX DU MOD√àLE\n",
    "        # -------------------------------\n",
    "        st.sidebar.subheader(\"üß† Choix du mod√®le\")\n",
    "        model_choice = st.sidebar.selectbox(\n",
    "            \"S√©lectionnez un algorithme :\",\n",
    "            [\"KNN\", \"SVM\", \"Random Forest\", \"R√©gression Logistique\"]\n",
    "        )\n",
    "\n",
    "        if st.sidebar.button(\"üöÄ Entra√Æner le mod√®le\"):\n",
    "            if model_choice == \"KNN\":\n",
    "                model = KNeighborsClassifier()\n",
    "            elif model_choice == \"SVM\":\n",
    "                model = SVC()\n",
    "            elif model_choice == \"Random Forest\":\n",
    "                model = RandomForestClassifier()\n",
    "            else:\n",
    "                model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "            # Entra√Ænement\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "            st.subheader(\"üìà R√©sultats du Mod√®le\")\n",
    "            st.write(f\"**Exactitude (Accuracy)** : {acc:.4f}\")\n",
    "            st.text(\"üìä Rapport de classification :\")\n",
    "            st.text(classification_report(y_test, y_pred))\n",
    "\n",
    "            # Matrice de confusion graphique\n",
    "            st.subheader(\"üîç Matrice de Confusion\")\n",
    "            fig, ax = plt.subplots()\n",
    "            sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", ax=ax)\n",
    "            st.pyplot(fig)\n",
    "\n",
    "        # -------------------------------\n",
    "        # 5Ô∏è‚É£ OPTIMISATION DES HYPERPARAM√àTRES\n",
    "        # -------------------------------\n",
    "        st.sidebar.subheader(\"üéØ Optimisation GridSearchCV\")\n",
    "\n",
    "        if st.sidebar.button(\"üîé Lancer l‚Äôoptimisation\"):\n",
    "            if model_choice == \"KNN\":\n",
    "                param_grid = {'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance']}\n",
    "                grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "            elif model_choice == \"Random Forest\":\n",
    "                param_grid = {\n",
    "                    'n_estimators': [50, 100, 200],\n",
    "                    'max_depth': [5, 10, None],\n",
    "                    'min_samples_split': [2, 5, 10]\n",
    "                }\n",
    "                grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')\n",
    "            else:\n",
    "                st.warning(\"‚ö†Ô∏è L‚Äôoptimisation est uniquement disponible pour KNN et Random Forest.\")\n",
    "                grid = None\n",
    "\n",
    "            if grid is not None:\n",
    "                with st.spinner(\"‚è≥ Recherche des meilleurs param√®tres...\"):\n",
    "                    grid.fit(X_train, y_train)\n",
    "                st.success(\"‚úÖ Optimisation termin√©e !\")\n",
    "                st.write(\"**Meilleurs param√®tres :**\", grid.best_params_)\n",
    "                st.write(\"**Meilleure pr√©cision (cross-validation)** :\", grid.best_score_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
